{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "\n",
    "pal = sns.color_palette()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "%%sh\n",
    "\n",
    "[ -f autotime.py ] && echo \"File exist\" || wget https://raw.githubusercontent.com/msampathkumar/ipython-autotime/master/autotime.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.92 ms\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "\n",
    "if os.path.isdir('data'):\n",
    "    QUORA_DATA_DIR = \"data/\"\n",
    "    GLOVE_DATA_DIR = \"data/\"\n",
    "else:\n",
    "    QUORA_DATA_DIR = \"/opt/datasets/quora/\"\n",
    "    GLOVE_DATA_DIR = \"/opt/datasets/glove/\"\n",
    "\n",
    "TRAIN_CSV = QUORA_DATA_DIR + 'train.csv'\n",
    "TEST_CSV = QUORA_DATA_DIR + 'test.csv'\n",
    "\n",
    "glove_840B_300d = GLOVE_DATA_DIR + 'glove.840B.300d.txt'\n",
    "GLOVE_DATA_FILE = glove_840B_300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.93 ms\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "MAX_SEQUENCE_LENGTH = 45\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the step by step guide to invest in share market in india?What is the step by step guide to invest in share market?', 'What is the story of Kohinoor (Koh-i-Noor) Diamond?What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', 'How can I increase the speed of my internet connection while using a VPN?How can Internet speed be increased by hacking through DNS?', 'Why am I mentally very lonely? How can I solve it?Find the remainder when [math]23^{24}[/math] is divided by 24,23?', 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?Which fish would survive in salt water?', \"Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\", 'Should I buy tiago?What keeps childern active and far from phone and video games?', 'How can I be a good geologist?What should I do to be a great geologist?', 'When do you use シ instead of し?When do you use \"&\" instead of \"and\"?', 'Motorola (company): Can I hack my Charter Motorolla DCX3400?How do I hack Motorola DCX3400 for free internet?']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Train Data\n",
    "train_feature_1_string = pd.Series(df_train['question1'].tolist()).astype(str)\n",
    "train_feature_2_string = pd.Series(df_train['question2'].tolist()).astype(str)\n",
    "\n",
    "target = pd.Series(df_train['is_duplicate'].tolist())\n",
    "\n",
    "all_train_qs = train_feature_1_string + train_feature_2_string\n",
    "\n",
    "# Test Data\n",
    "test_feature_1_string = pd.Series(df_test['question1'].tolist()).astype(str)\n",
    "test_feature_2_string = pd.Series(df_test['question2'].tolist()).astype(str)\n",
    "\n",
    "all_test_qs = test_feature_1_string + test_feature_2_string\n",
    "\n",
    "all_qs = all_train_qs + all_test_qs\n",
    "\n",
    "print(all_train_qs.tolist()[:10])\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Text Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "dt_all_qids = df_train.qid1 + df_train.qid1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(dt_all_qids.value_counts(), bins=50)\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.title('Log-Histogram of question appearance counts')\n",
    "plt.xlabel('Number of occurences of question')\n",
    "plt.ylabel('Number of questions')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.31 ms\n"
     ]
    }
   ],
   "source": [
    "all_qids = df_train.qid1 + df_train.qid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 267 ms\n"
     ]
    }
   ],
   "source": [
    "train_qs = df_train.question1 + df_train.question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of question pairs for training: 404290\n",
      "Duplicate pairs: 36.92%\n",
      "Total number of questions in the training data: 404289\n",
      "Number of questions that appear multiple times: 50205\n",
      "Total number of questions in Quora dataset: 2345796\n",
      "time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "total_ques_pairs = len(df_train)\n",
    "print('Total number of question pairs for training: {}'.format(total_ques_pairs))\n",
    "\n",
    "duplicate_ques_pairs = round(df_train['is_duplicate'].mean()*100, 2)\n",
    "print('Duplicate pairs: {}%'.format(duplicate_ques_pairs))\n",
    "\n",
    "unique_qids = len(np.unique(train_qs.fillna(\"\")))\n",
    "print('Total number of questions in the training data: {}'.format(unique_qids))\n",
    "\n",
    "print('Number of questions that appear multiple times: {}'.format(np.sum(all_qids.value_counts() > 1)))\n",
    "\n",
    "print(\"Total number of questions in Quora dataset: {}\".format(len(all_qs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dist_train = train_qs.apply(len)\n",
    "# dist_test = test_qs.apply(len)\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.hist(dist_train, bins=200, range=[0, 200], color=pal[2], normed=True, label='train')\n",
    "# plt.hist(dist_test, bins=200, range=[0, 200], color=pal[1], normed=True, alpha=0.5, label='test')\n",
    "# plt.title('Normalised histogram of character count in questions', fontsize=15)\n",
    "# plt.legend()\n",
    "# plt.xlabel('Number of characters', fontsize=15)\n",
    "# plt.ylabel('Probability', fontsize=15)\n",
    "\n",
    "# print('mean-train {:.2f} std-train {:.2f} mean-test {:.2f} std-test {:.2f} max-train {:.2f} max-test {:.2f} max-train{:.2f}'.format(dist_train.mean(), \n",
    "#                           dist_train.std(), dist_test.mean(), dist_test.std(), dist_train.max(), dist_test.max(), dist_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "# cloud = WordCloud(width=1440, height=1080).generate(\" \".join(train_qs.astype(str)))\n",
    "# plt.figure(figsize=(20, 15))\n",
    "# plt.imshow(cloud)\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "if ('embeddings_index' not in dir()):\n",
    "    print('Indexing word vectors.')\n",
    "    embeddings_index = {}\n",
    "    with codecs.open(GLOVE_DATA_FILE, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # line for '<key> <vector coeffecients>'\n",
    "            # Example 'A 0.2341 0.12313 0.31432 0.123414 ....'\n",
    "            values = line.split(' ')\n",
    "            embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "else:\n",
    "    print('Skipped to save some time!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\t-0.082752\t0.67204\n",
      ".\t0.012001\t0.20751\n",
      "the\t0.27204\t-0.06203\n",
      "and\t-0.18567\t0.066008\n",
      "to\t0.31924\t0.06316\n",
      "of\t0.060216\t0.21799\n",
      "a\t0.043798\t0.024779\n",
      "in\t0.089187\t0.25792\n",
      "\"\t-0.075242\t0.57337\n",
      ":\t0.008746\t0.33214\n",
      "is\t-0.084961\t0.502\n",
      "for\t-0.17224\t0.18234\n",
      "I\t0.1941\t0.22603\n",
      ")\t-0.27142\t0.047374\n",
      "(\t-0.18024\t0.0084106\n",
      "that\t0.09852\t0.25001\n",
      "-\t-0.20688\t0.66724\n",
      "on\t-0.070186\t0.15274\n",
      "you\t-0.11076\t0.30786\n",
      "with\t-0.099534\t0.028202\n",
      "time: 432 ms\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# sample of how GLOVE_DATA_FILE\n",
    "\n",
    "head -n20 data/glove.840B.300d.txt | awk -F\" \" '{ print $1\"\\t\"$2\"\\t\"$3 }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.22 ms\n"
     ]
    }
   ],
   "source": [
    "# all_test_qs[:5].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "words_corpus = ''\n",
    "\n",
    "for msg in all_test_qs:\n",
    "    words_corpus += ' '\n",
    "    words_corpus += msg\n",
    "    \n",
    "words_corpus = set(words_corpus.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "words_corpus = ' '.join(words_corpus)\n",
    "\n",
    "special_chars = set([ i for i in words_corpus if not i.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.23 ms\n"
     ]
    }
   ],
   "source": [
    "len(special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.8 ms\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the best medication equation erectile dysfunction?How do I out get rid of Erectile Dysfunction?'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.72 ms\n"
     ]
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the best medication equation erectile dysfunction?how do i out get rid of erectile dysfunction?\n",
      "time: 3.61 ms\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "accepted_special_chars = set(''' <\\/>|?'\"+=-*&^%$#@!_.;:{}()[]~!@#$%^&*()_+'''  +\n",
    "                             string.ascii_lowercase +  string.digits)\n",
    "\n",
    "print(''.join([i for i in msg.lower() if i in accepted_special_chars]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words_corpus = list(words_corpus)\n",
    "\n",
    "words_corpus[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "special_chars_bag = []\n",
    "\n",
    "for each in all_test_qs[1].sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# embeddings_index['best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# all_questions_text = train_feature_1_text + train_feature_2_text + test_feature_1_text + test_feature_2_text\n",
    "# all_questions_text = list(filter(lambda q: type(q) == str, all_questions_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ques_lengths = list(map(lambda q: len(str(q).split(' ')) if(type(q) is str) else 0, all_questions_text))\n",
    "# #Beware the questions has nan and numbers\n",
    "\n",
    "# print(max(ques_lengths))   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# def getTokenizeModel(list_of_all_string, max_number_words):\n",
    "#     tokenizer = Tokenizer(nb_words=max_number_words)\n",
    "#     tokenizer.fit_on_texts(dt_all_questions_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %time\n",
    "# tokenizer = Tokenizer(nb_words=dt_MAX_NB_WORDS)\n",
    "# tokenizer.fit_on_texts(all_questions_text)\n",
    "# train_sequences_1 = dt_tokenizer.texts_to_sequences(train_feature_1_text)\n",
    "# train_sequences_2 = dt_tokenizer.texts_to_sequences(train_feature_2_text)\n",
    "# word_index = tokenizer.word_index\n",
    "# print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# dt_test_sequences_1 = tokenizer.texts_to_sequences(test_feature_1_text)\n",
    "# dt_test_sequences_2 = tokenizer.texts_to_sequences(test_feature_2_text)\n",
    "\n",
    "# data_1 = pad_sequences(train_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# data_2 = pad_sequences(train_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# labels = np.array(labels)\n",
    "# print('Shape of data tensor:', data_1.shape)\n",
    "# print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# test_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# test_labels = np.array(test_labels)\n",
    "# del test_sequences_1\n",
    "# del test_sequences_2\n",
    "# del train_sequences_1\n",
    "# del train_sequences_2\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l = [\"just say a word\",\"of some length\"]\n",
    "ll = list(map(lambda l: l.split(\" \"), l))\n",
    "seq_length = 5\n",
    "ll\n",
    "e = {\"just\": [0,0,0,0,1],\n",
    "     \"say\" : [0,0,0,1,1],\n",
    "     \"a\" : [0,1,1,1,0],\n",
    "     \"word\" : [1,0,0,1,0],\n",
    "     \"of\" : [0,1,0,1,0],\n",
    "     \"some\" : [0,1,0,1,0],\n",
    "     \"length\" : [0,0,1,1,0],\n",
    "     '<PAD>': [0,0,0,0,0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# list of words --> lows\n",
    "\n",
    "from pprint import pprint as pp\n",
    "\n",
    "def lows_padding(list_of_words, seq_length=5, append=True):\n",
    "    \"\"\"Pads/slices given bag of words for specified length.\"\"\"\n",
    "    if len(list_of_words) == seq_length:\n",
    "        return list_of_words\n",
    "    if len(list_of_words) > seq_length:\n",
    "        return list_of_words[:seq_length]\n",
    "    \n",
    "    tmp = ['<PAD>' for i in range(seq_length - len(list_of_words))]\n",
    "    if append:\n",
    "        return list_of_words + tmp\n",
    "    return  tmp + list_of_words\n",
    "\n",
    "def lows_embedding(list_of_words, serializer):\n",
    "    \"\"\"To serializer/string Tokenize the list of words.\"\"\"\n",
    "    return list(map(lambda x: serializer[x], list_of_words))\n",
    "\n",
    "def lows_transformer(list_of_words, serializer, seq_length, append):\n",
    "    \"\"\"To pad the given list of words and serialiase them.\"\"\"\n",
    "    return lows_embedding(lows_padding(list_of_words, seq_length, append),\n",
    "                          serializer=e)\n",
    "\n",
    "bag_of_lows_transformer = lambda list_of_words: lows_transformer(list_of_words, serializer=e,\n",
    "                                                                 seq_length=4, append=True)\n",
    "\n",
    "pp(list(map(bag_of_lows_transformer, ll)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bag_of_lows_transformer(['just', 'say', 'a', 'word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bag = list(map(bag_of_lows_transformer, ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_feature(embed_dict, list_of_strings, max_seq_length, embed_dim):\n",
    "    features = np.zeros((len(list_of_strings), max_seq_length, embed_dim), dtype=float)\n",
    "    list_of_bag_of_words = map(lambda l: list_of_words_padding(list_of_words=l.split(),\n",
    "                                                                seq_length=max_seq_length,\n",
    "                                                                append=True),\n",
    "                                list_of_strings)\n",
    "    return list_of_bag_of_words\n",
    "\n",
    "list(get_feature(e, l, 7, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample = df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample.question1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 256\n",
    "lstm_layers = 1\n",
    "batch_size = 250\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the graph object\n",
    "graph = tf.Graph()\n",
    "# Add nodes to the graph\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, None, None], name='inputs') #[Number of ques, Seq/Ques Length, Embed Dims]\n",
    "    labels_ = tf.placeholder(tf.float32, [None, None], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "http://suriyadeepan.github.io/2016-06-28-easy-seq2seq/\n",
    "\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
    "\n",
    "https://github.com/yuhaozhang/sentence-convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "500 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
